{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tts_models/multilingual/multi-dataset/xtts_v2', 'tts_models/multilingual/multi-dataset/xtts_v1.1', 'tts_models/multilingual/multi-dataset/your_tts', 'tts_models/multilingual/multi-dataset/bark', 'tts_models/bg/cv/vits', 'tts_models/cs/cv/vits', 'tts_models/da/cv/vits', 'tts_models/et/cv/vits', 'tts_models/ga/cv/vits', 'tts_models/en/ek1/tacotron2', 'tts_models/en/ljspeech/tacotron2-DDC', 'tts_models/en/ljspeech/tacotron2-DDC_ph', 'tts_models/en/ljspeech/glow-tts', 'tts_models/en/ljspeech/speedy-speech', 'tts_models/en/ljspeech/tacotron2-DCA', 'tts_models/en/ljspeech/vits', 'tts_models/en/ljspeech/vits--neon', 'tts_models/en/ljspeech/fast_pitch', 'tts_models/en/ljspeech/overflow', 'tts_models/en/ljspeech/neural_hmm', 'tts_models/en/vctk/vits', 'tts_models/en/vctk/fast_pitch', 'tts_models/en/sam/tacotron-DDC', 'tts_models/en/blizzard2013/capacitron-t2-c50', 'tts_models/en/blizzard2013/capacitron-t2-c150_v2', 'tts_models/en/multi-dataset/tortoise-v2', 'tts_models/en/jenny/jenny', 'tts_models/es/mai/tacotron2-DDC', 'tts_models/es/css10/vits', 'tts_models/fr/mai/tacotron2-DDC', 'tts_models/fr/css10/vits', 'tts_models/uk/mai/glow-tts', 'tts_models/uk/mai/vits', 'tts_models/zh-CN/baker/tacotron2-DDC-GST', 'tts_models/nl/mai/tacotron2-DDC', 'tts_models/nl/css10/vits', 'tts_models/de/thorsten/tacotron2-DCA', 'tts_models/de/thorsten/vits', 'tts_models/de/thorsten/tacotron2-DDC', 'tts_models/de/css10/vits-neon', 'tts_models/ja/kokoro/tacotron2-DDC', 'tts_models/tr/common-voice/glow-tts', 'tts_models/it/mai_female/glow-tts', 'tts_models/it/mai_female/vits', 'tts_models/it/mai_male/glow-tts', 'tts_models/it/mai_male/vits', 'tts_models/ewe/openbible/vits', 'tts_models/hau/openbible/vits', 'tts_models/lin/openbible/vits', 'tts_models/tw_akuapem/openbible/vits', 'tts_models/tw_asante/openbible/vits', 'tts_models/yor/openbible/vits', 'tts_models/hu/css10/vits', 'tts_models/el/cv/vits', 'tts_models/fi/css10/vits', 'tts_models/hr/cv/vits', 'tts_models/lt/cv/vits', 'tts_models/lv/cv/vits', 'tts_models/mt/cv/vits', 'tts_models/pl/mai_female/vits', 'tts_models/pt/cv/vits', 'tts_models/ro/cv/vits', 'tts_models/sk/cv/vits', 'tts_models/sl/cv/vits', 'tts_models/sv/cv/vits', 'tts_models/ca/custom/vits', 'tts_models/fa/custom/glow-tts', 'tts_models/bn/custom/vits-male', 'tts_models/bn/custom/vits-female', 'tts_models/be/common-voice/glow-tts', 'vocoder_models/universal/libri-tts/wavegrad', 'vocoder_models/universal/libri-tts/fullband-melgan', 'vocoder_models/en/ek1/wavegrad', 'vocoder_models/en/ljspeech/multiband-melgan', 'vocoder_models/en/ljspeech/hifigan_v2', 'vocoder_models/en/ljspeech/univnet', 'vocoder_models/en/blizzard2013/hifigan_v2', 'vocoder_models/en/vctk/hifigan_v2', 'vocoder_models/en/sam/hifigan_v2', 'vocoder_models/nl/mai/parallel-wavegan', 'vocoder_models/de/thorsten/wavegrad', 'vocoder_models/de/thorsten/fullband-melgan', 'vocoder_models/de/thorsten/hifigan_v1', 'vocoder_models/ja/kokoro/hifigan_v1', 'vocoder_models/uk/mai/multiband-melgan', 'vocoder_models/tr/common-voice/hifigan', 'vocoder_models/be/common-voice/hifigan', 'voice_conversion_models/multilingual/vctk/freevc24']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmazu\\Documents\\GitHub\\BlinkStory\\.venv\\Lib\\site-packages\\TTS\\tts\\layers\\xtts\\xtts_manager.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.speakers = torch.load(speaker_file_path)\n",
      "c:\\Users\\pmazu\\Documents\\GitHub\\BlinkStory\\.venv\\Lib\\site-packages\\trainer\\io.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=map_location, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Get device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# List available üê∏TTS models\n",
    "print(TTS().list_models())\n",
    "\n",
    "# Init TTS\n",
    "tts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output.wav'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tts.tts_to_file(text=\"Cats jumping around everywhere and it's so crazy it's like they're exploding\", speaker_wav=[\"./audio/output2.wav\"], language=\"en\", file_path=\"output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35644\n"
     ]
    }
   ],
   "source": [
    "# get audio length\n",
    "import wave\n",
    "wav = wave.open(\"./audio/output2.wav\", \"rb\")\n",
    "print(wav.getnframes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAV file saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "\n",
    "with open(\"./audio/main.wav\", \"rb\") as audio:\n",
    "    audio_data = audio.read()\n",
    "\n",
    "# Assuming these audio parameters (you need to adjust them based on your audio)\n",
    "num_channels = 2        # 1 for mono, 2 for stereo\n",
    "sample_width = 2        # Sample width in bytes (e.g., 2 for 16-bit audio)\n",
    "frame_rate = 48000      # Frame rate (samples per second)\n",
    "num_frames = len(audio_data) // (num_channels * sample_width)  # Calculate total frames\n",
    "\n",
    "# Open a new wave file\n",
    "with wave.open(\"./audio/output.wav\", \"wb\") as output_wave:\n",
    "    # Set the parameters for the output file\n",
    "    output_wave.setnchannels(num_channels)\n",
    "    output_wave.setsampwidth(sample_width)\n",
    "    output_wave.setframerate(frame_rate)\n",
    "    # Write audio data to the wave file for only 15 seconds\n",
    "    output_wave.writeframes(audio_data[:frame_rate * 15 * num_channels * sample_width])\n",
    "    \n",
    "print(\"WAV file saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter the path to the audio file here\n",
    "src_audio = r\"./audio/output.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\python.exe: can't open file 'c:\\\\Users\\\\pmazu\\\\Documents\\\\GitHub\\\\BlinkStory\\\\tools\\\\vqgan\\\\inference.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python tools/vqgan/inference.py \\\n",
    "    -i {src_audio} \\\n",
    "    --checkpoint-path \"checkpoints/fish-speech-1.4/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\python.exe: can't open file 'c:\\\\Users\\\\pmazu\\\\Documents\\\\GitHub\\\\BlinkStory\\\\tools\\\\inference.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# run tools.inference with args\n",
    "!python tools/inference.py \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pmazu\\Documents\\GitHub\\BlinkStory\\.venv\\Lib\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "import stable_whisper\n",
    "model = stable_whisper.load_model('base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the encoding on all the files in ./audio (recursive)\n",
    "import os\n",
    "\n",
    "# Assuming these audio parameters (you need to adjust them based on your audio)\n",
    "num_channels = 2        # 1 for mono, 2 for stereo\n",
    "sample_width = 2        # Sample width in bytes (e.g., 2 for 16-bit audio)\n",
    "frame_rate = 48000      # Frame rate (samples per second)\n",
    "num_frames = len(audio_data) // (num_channels * sample_width)  # Calculate total frames\n",
    "\n",
    "user_folders = os.listdir('./audio')\n",
    "\n",
    "# Open a new wave file\n",
    "for user_folder in user_folders:\n",
    "    for file in os.listdir(f\"./audio/{user_folder}\"):\n",
    "        with open(f\"./audio/{user_folder}/{file}\", \"rb\") as f:\n",
    "            audio_data = f.read()\n",
    "            with wave.open(f\"./audio/{user_folder}/{file}\", \"wb\") as output_wave:\n",
    "                # Set the parameters for the output file\n",
    "                output_wave.setnchannels(num_channels)\n",
    "                output_wave.setsampwidth(sample_width)\n",
    "                output_wave.setframerate(frame_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 46.86sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 175.41sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 121.45sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:01<00:00, 12.58sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 34.20sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 35.17sec/s] \n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 43.79sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 40.42sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 70.90sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 70.57sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 68.94sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 40.75sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 33.04sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 29.91sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 42.67sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 0.12/0.12 [00:00<00:00, 47.88sec/s]\n",
      "c:\\Users\\pmazu\\Documents\\GitHub\\BlinkStory\\.venv\\Lib\\site-packages\\stable_whisper\\result.py:1835: UserWarning: Cannot clamp due to missing/no word-timestamps\n",
      "  warnings.warn('Cannot clamp due to missing/no word-timestamps')\n",
      "c:\\Users\\pmazu\\Documents\\GitHub\\BlinkStory\\.venv\\Lib\\site-packages\\stable_whisper\\whisper_word_level\\original_whisper.py:686: UserWarning: Failed to transcribe audio. Result contains no text. \n",
      "  warnings.warn(f'Failed to {task} audio. Result contains no text. ')\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 35.75sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 78.73sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 71.77sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 69.92sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 69.76sec/s]\n",
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 48.00sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.98/1.98 [00:00<00:00, 16.92sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 40.64sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.86/11.86 [00:00<00:00, 67.18sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 55.65sec/s]\n",
      "Transcribe:   0%|          | 0/7.44 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.44/7.44 [00:00<00:00, 29.75sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.54/1.54 [00:00<00:00, 17.70sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe:   0%|          | 0/15.0 [00:00<?, ?sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 26.71sec/s]\n",
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 114.91sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.82/2.82 [00:00<00:00, 22.29sec/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribe: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15.0/15.0 [00:00<00:00, 115.78sec/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: english\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# find any segments of talking that are longer than 6 seconds\n",
    "import wave\n",
    "for user_folder in user_folders:\n",
    "    for file in os.listdir(f\"./audio/{user_folder}\"):\n",
    "        audio_path = f\"./audio/{user_folder}/{file}\"\n",
    "        result = model.transcribe(audio_path)\n",
    "        # save transcript with clip\n",
    "        with open(f\"./audio/{user_folder}/{file}.txt\", \"w\") as f:\n",
    "            f.write(result.text)\n",
    "        # with open(f\"./audio/output_{segment.start}_{segment.end}.wav\", \"wb\") as f:\n",
    "        #     audio_file = wave.open(audio_path)\n",
    "        #     f.write(audio_file.readframes(int((segment.end - segment.start) * audio_file.getframerate())))\n",
    "        # with open(f\"./audio/output_{segment.start}_{segment.end}.txt\", \"w\") as f:\n",
    "        #     f.write(segment.text)\n",
    "        # print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import requests\n",
    "import ormsgpack\n",
    "from tools.commons import ServeReferenceAudio, ServeTTSRequest\n",
    "from tools.file import audio_to_bytes, read_ref_text\n",
    "\n",
    "\n",
    "async def synthesize_and_stream_audio(vc, text, reference_audio, reference_text, api_key=\"YOUR_API_KEY\"):\n",
    "    # Process reference audio and text\n",
    "    byte_audios = [audio_to_bytes(ref_audio) for ref_audio in reference_audio] if reference_audio else []\n",
    "    ref_texts = [read_ref_text(ref_text) for ref_text in reference_text] if reference_text else []\n",
    "    \n",
    "    data = {\n",
    "        \"text\": text,\n",
    "        \"references\": [\n",
    "            ServeReferenceAudio(audio=ref_audio, text=ref_text)\n",
    "            for ref_text, ref_audio in zip(ref_texts, byte_audios)\n",
    "        ],\n",
    "        \"streaming\": True,\n",
    "        \"format\": \"wav\",\n",
    "    }\n",
    "\n",
    "    pydantic_data = ServeTTSRequest(**data)\n",
    "\n",
    "    response = requests.post(\n",
    "        \"http://127.0.0.1:8080/v1/tts\",\n",
    "        data=ormsgpack.packb(pydantic_data, option=ormsgpack.OPT_SERIALIZE_PYDANTIC),\n",
    "        stream=True,\n",
    "        headers={\n",
    "            \"authorization\": f\"Bearer {api_key}\",\n",
    "            \"content-type\": \"application/msgpack\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        audio_format = pyaudio.paInt16  # Assuming 16-bit PCM format\n",
    "        wf = pyaudio.PyAudio()\n",
    "        stream = wf.open(format=audio_format, channels=1, rate=44100, output=True)\n",
    "\n",
    "        # Play the audio stream in Discord VC\n",
    "        try:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    stream.write(chunk)\n",
    "                    # vc.send_audio_packet(chunk, encode=False)  # Send to discord voice channel\n",
    "        finally:\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            wf.terminate()\n",
    "    else:\n",
    "        print(f\"Request failed with status code {response.status_code}\")\n",
    "        print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just pick one file that has a transcript\n",
    "reference_audio = []\n",
    "reference_text = []\n",
    "for user_folder in user_folders:\n",
    "    for file in os.listdir(f\"./audio/{user_folder}\"):\n",
    "        if file.endswith(\".txt\"):\n",
    "            reference_text.append(f\"./audio/{user_folder}/{file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "chosen_reference_text = random.choice(reference_text)\n",
    "chosen_reference_audio = f\"./audio/{chosen_reference_text.split('/')[-2]}/{chosen_reference_text.split('/')[-1].replace('.txt', '')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "await synthesize_and_stream_audio(None, \"you absolute loser what\", [chosen_reference_audio], [chosen_reference_text])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
